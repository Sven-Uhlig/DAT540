{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 06 - Advance pandas operations and data cleaning \n",
    "## In this lab we are covering topics belonging to:\n",
    "        - Data Aggregation\n",
    "        - Apply general split-array-combine\n",
    "        - Techniques for Method Chaining\n",
    "        - Pivot Tables and Cross Tabulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Import pandas as pd and numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Given a dataframe (df), consider grouping the dataframe with the key of \"key1\" and analyse the returned object. Is the object returned also the Dataframe? Print the object to see what is returns?\n",
    "\n",
    "- With groupby method, get the average values of data1 and data2 and calculate the sum of the data1 and data2.\n",
    "- Also use describe() method to display the output. Analyze the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'key1': ['a', 'a', 'b', 'b', 'a'],\n",
    "                  'key2': ['one', 'two', 'one', 'two', 'one'],\n",
    "                  'data1': np.random.rand(5),\n",
    "                  'data2': np.random.rand(5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Using the previous dataframe df, calculate the mean, sum and the standard deviation of data1 and data2 using aggregate in a single line.\n",
    "\n",
    "a. The key1 and key2 columns have character and string values which produces NaN while calculating the mean and the standard deviation.\n",
    "Try to use the dataframe to calculate everything, see the results and drop columns with NaN values. \n",
    "\n",
    "b. Try a different approach and use only columns to perform the same operations (mean, std, sum) in a single line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. See the below figure and create a dataframe as shown in the input. Split the data, apply sum and print the combined data.\n",
    "\n",
    "Hint: Concept of split-apply-combine. Use groupby apply sum and combine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://jakevdp.github.io/PythonDataScienceHandbook/figures/03.08-split-apply-combine.png\" width=\"800\" height=\"400\">\n",
    "\n",
    "Image Source: https://jakevdp.github.io/PythonDataScienceHandbook/figures/03.08-split-apply-combine.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO\n",
    "# figframe = pd.DataFrame({\n",
    "#     \"key\" : ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "#     \"data\" : range(1, 7)\n",
    "# })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Given the following dataframe \"sales\", \n",
    "\n",
    "a. Convert the column values \"date\" from string to datetime. (use Pandas to_datetime) \n",
    "\n",
    "b. Generate pivot table to summarize the data in terms of sales_number according to the date and the region. \n",
    "\n",
    "Hint: Use pivot_table function. Indicate the index as date and region, value as the number and apply sum to the number.\n",
    "\n",
    "c. Generate pivot table to show each day sales number. Show only date and total number of sales value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.DataFrame({\n",
    "    \"region\" : ['SVG', 'OSL', 'BER', 'OSL', 'SVG', 'SVG', 'SVG', 'OSL', 'BER', 'OSL'],\n",
    "    \"sales_number\" : [22, 45, 87, 76, 99, 29, 21, 67, 66, 98],\n",
    "    \"date\" : ['050822', '050822', '090722', '220922', '020922', '220722', '220722', '050822', '090722', '220922']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Now consider the same dataframe \"sales\" to create a copy of dataframe sales_copy and use this dataframe.\n",
    "\n",
    "a. Create a new column for sales price where the column name would be 'total_sales_kr' and the result should be the 110 times multiple of sales_number.\n",
    "\n",
    "b. Rename the column name \"region\" to \"city\".\n",
    "\n",
    "Perform (a) and (b) using Method Chaining technique. You may use lamda function for task (a).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6. Create a function named dropsn which takes an argument of dataframe, drops column name \"sales_number\" and returns a updated dataframe. \n",
    "\n",
    "a. Use the function with pipe method in the same sales copy dataframe you created in the previous question to see the result. (Updated copy of sales dataframe without sales_number). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##a:  TO DO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7. The tips dataset can be loaded from Seaborn library as shown below.\n",
    "\n",
    "a. Display and analyse the dataset.\n",
    "\n",
    "b. Create a new column named \"tip_percentage\" which equals to the tip of the day divided by the total_bill.\n",
    "\n",
    "c. Group by or pivot based on the \"day\" and \"sex\". Calculate average value of tip and tip_percentage for the day and for corresponding sex.\n",
    "\n",
    "You can install seaborn using \"!pip install seaborn\". Seaborn offers small datasets adn visualization tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn package has a set of sample datasets: https://github.com/mwaskom/seaborn-data\n",
    "# We can load them as a pandas DataFrame\n",
    "import seaborn as sns\n",
    "\n",
    "tips = sns.load_dataset('tips')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##b:  TO DO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##c:  TO DO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8. Using the same dataset,\n",
    "\n",
    "a. Create a sepearate dataframe with the \"sex\" and \"tip\". With the new dataframe, group the dataframe by sex and apply a function (either user defined or lambda) which would return the describe() of the group.\n",
    "\n",
    "--- The result would give the counts of total tips by each Male or Female, mean, std, .... (everything the describe method gives)\n",
    "\n",
    "b. Create a new dataframe applying reset_index() to the resulting dataframe from (a). See the result and analyze what happens.\n",
    "\n",
    "c. Rename the columns from dataframe (b): level_1 to statistics and tip to values. Group again by 'sex' and display results setting columns as values in statistics and values as value to each of the column.\n",
    "\n",
    "For (c) you can use Pandas CrossTab to generate a Contingency Table.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Contingency_table\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.crosstab.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "##a: TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##b:  TO DO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##c:  TO DO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9. Import the titantic dataset with seaborn.\n",
    "\n",
    "a. Display the dataset information for analysis.\n",
    "\n",
    "b. Select only 'sex' and 'survived' columns. fill the NA values and use Pandas get_dummies to create a dataframe. Use all of these in the single line using the Method Chaining.\n",
    "\n",
    "-- fill NA values using amputation methods, you may use np.mean\n",
    "-- Get to know what get_dummies function does.\n",
    "\n",
    "-- In (b), analyze carefully on how you obtain the result, specifically the usage of get_dummies, how you get there and why you used specified process to get the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##a: TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##b: TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10. Using the same titanic dataset from Q.9,\n",
    "\n",
    "a. Create a function to convert the format of sex from Male to M and Female to F. \n",
    "\n",
    "b. Label the age, 0-15 == 'Less than 15', 15 - 19 == 'Teen', 19 - 60 == 'Adult' and 60 - 110 == 'Senior', and create a column named 'age_group' to store these values.\n",
    "\n",
    "c. Select passengers departing from Southampton i.e embark_town == Southampton\n",
    "\n",
    "d. Drop n/a values: Create function for (a), (b). Method Chain to create seperately,\n",
    "</br> use contingency table to verify the results.\n",
    "\n",
    "Hint Useful functions: pd.replace, pd.cut, df.query(),\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##a: TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##b: TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##c: TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##d: TO DO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b0ba7010dbd3f71a802994001586bf1038832a78f22f020283b3da6f02029a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
